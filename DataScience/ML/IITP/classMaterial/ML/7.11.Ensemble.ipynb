{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", header=None)\n",
    "\n",
    "X = df.iloc[:,0:56]\n",
    "y = df.iloc[:,57]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.235</td>\n",
       "      <td>3.521</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.209</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2279</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.482</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.631</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3688</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2    3    4    5     6     7     8     9   ...   46   47  \\\n",
       "1507  0.0  0.17  0.00  0.0  0.0  0.0  0.17  0.52  0.00  0.17  ...  0.0  0.0   \n",
       "1652  0.7  0.00  1.06  0.0  0.0  0.0  0.00  1.41  0.35  0.35  ...  0.0  0.0   \n",
       "2279  0.0  0.00  1.58  0.0  0.0  0.0  0.00  0.00  0.00  0.00  ...  0.0  0.0   \n",
       "2106  0.0  0.00  0.00  0.0  0.0  0.0  0.00  0.00  0.00  2.56  ...  0.0  0.0   \n",
       "3688  0.0  0.00  0.00  0.0  0.0  0.0  0.00  0.00  0.00  0.00  ...  0.0  0.0   \n",
       "\n",
       "         48     49     50     51     52     53     54  55  \n",
       "1507  0.029  0.147  0.029  0.117  0.058  0.235  3.521  39  \n",
       "1652  0.000  0.117  0.000  0.353  0.000  0.000  1.209  13  \n",
       "2279  0.000  0.149  0.000  0.149  0.000  0.000  1.482  10  \n",
       "2106  0.000  0.194  0.194  0.000  0.000  0.000  3.631  17  \n",
       "3688  0.000  0.000  0.000  0.000  0.000  0.000  1.000   1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.97 (+/- 0.01) [Logistic Regression]\n",
      "ROC AUC: 0.89 (+/- 0.02) [Decision Tree]\n",
      "ROC AUC: 0.97 (+/- 0.01) [Naive Bayesian]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs')\n",
    "tree = DecisionTreeClassifier()\n",
    "svm = svm.SVC(probability=True, gamma='auto')\n",
    "\n",
    "lr = Pipeline([['sc', StandardScaler()],\n",
    "                  ['clf', clf]])\n",
    "\n",
    "clf_labels = ['Logistic Regression', 'Decision Tree', 'Naive Bayesian']\n",
    "\n",
    "def cv(all_clf, clf_labels):\n",
    "    for clf, label in zip(all_clf, clf_labels):\n",
    "        scores = cross_val_score(estimator=clf,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=10,\n",
    "                             scoring='roc_auc')\n",
    "        print(\"ROC AUC: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "        \n",
    "cv([lr, tree, svm], clf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "class MajorityVoteClassifier(BaseEstimator, \n",
    "                             ClassifierMixin):\n",
    "    def __init__(self, classifiers={}, vote='classlabel', weights=None):\n",
    "\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value\n",
    "                                  in _name_estimators(classifiers)}\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(\"vote must be 'probability' or 'classlabel'\"\n",
    "                             \"; got (vote=%r)\"\n",
    "                             % self.vote)\n",
    "\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d classifiers'\n",
    "                             % (len(self.weights), len(self.classifiers)))\n",
    "\n",
    "        self.lablenc_ = LabelEncoder()\n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X, self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1)\n",
    "        else:  # 'classlabel' vote\n",
    "\n",
    "            #  Collect results from clf.predict calls\n",
    "            predictions = np.asarray([clf.predict(X)\n",
    "                                      for clf in self.classifiers_]).T\n",
    "\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                                      lambda x:\n",
    "                                      np.argmax(np.bincount(x,\n",
    "                                                weights=self.weights)),\n",
    "                                      axis=1,\n",
    "                                      arr=predictions)\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                             for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.97 (+/- 0.01) [Logistic Regression]\n",
      "ROC AUC: 0.90 (+/- 0.02) [Decision Tree]\n",
      "ROC AUC: 0.97 (+/- 0.01) [Naive Bayesian]\n",
      "ROC AUC: 0.98 (+/- 0.01) [Majority Voting]\n"
     ]
    }
   ],
   "source": [
    "mv_clf = MajorityVoteClassifier(classifiers=[lr, tree, svm])\n",
    "\n",
    "clf_labels += ['Majority Voting']\n",
    "all_clf = [lr, tree, svm, mv_clf]\n",
    "\n",
    "cv(all_clf, clf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.97 (+/- 0.01) [Logistic Regression]\n",
      "ROC AUC: 0.90 (+/- 0.02) [Decision Tree]\n",
      "ROC AUC: 0.97 (+/- 0.01) [Naive Bayesian]\n",
      "ROC AUC: 0.98 (+/- 0.01) [Majority Voting]\n"
     ]
    }
   ],
   "source": [
    "mv_clf = MajorityVoteClassifier(classifiers=[lr, tree, svm], vote='probability')\n",
    "cv(all_clf, clf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215075164307263"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 0 - origin : 8.8, prediction : 8.424999999999997\n",
      "Instance 1 - origin : 23.8, prediction : 23.627999999999982\n"
     ]
    }
   ],
   "source": [
    "predictSample = X_test[[10, 20]]\n",
    "print(\"Instance 0 - origin : %s, prediction : %s\" % (str(y_test[10]), str(rf.predict(predictSample[0].reshape(1,-1))[0])))\n",
    "print(\"Instance 1 - origin : %s, prediction : %s\" % (str(y_test[20]), str(rf.predict(predictSample[1].reshape(1,-1))[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance : 0\n",
      "Bias (trainset mean) : 22.695071\n",
      "Feature contributions:\n",
      "LSTAT -6.56\n",
      "CRIM -4.05\n",
      "RM -1.87\n",
      "NOX -0.88\n",
      "TAX -0.37\n",
      "DIS -0.29\n",
      "AGE -0.25\n",
      "PTRATIO -0.0\n",
      "B -0.0\n",
      "ZN 0.0\n",
      "INDUS 0.0\n",
      "CHAS 0.0\n",
      "RAD 0.0\n",
      "prediction : 8.425000 \n",
      "bias + sum of contribution : 8.425000 \n",
      "--------------------\n",
      "Instance : 1\n",
      "Bias (trainset mean) : 22.695071\n",
      "Feature contributions:\n",
      "LSTAT 5.81\n",
      "RM -4.17\n",
      "AGE -0.3\n",
      "TAX -0.21\n",
      "INDUS -0.14\n",
      "CRIM 0.1\n",
      "B -0.1\n",
      "DIS -0.08\n",
      "ZN 0.06\n",
      "PTRATIO -0.04\n",
      "RAD -0.01\n",
      "NOX 0.01\n",
      "CHAS -0.0\n",
      "prediction : 23.628000 \n",
      "bias + sum of contribution : 23.628000 \n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "prediction, bias, contributions = ti.predict(rf, predictSample)\n",
    "for i in range(len(predictSample)):\n",
    "    print(\"Instance : %d\" % i)\n",
    "    print(\"Bias (trainset mean) : %f\" % bias[i])\n",
    "    print(\"Feature contributions:\")\n",
    "    for c, feature in sorted(zip(contributions[i], \n",
    "                                 boston.feature_names), \n",
    "                             key=lambda x: -abs(x[0])):\n",
    "        print(feature, round(c, 2))\n",
    "    print('prediction : %f ' % prediction[i])\n",
    "    print('bias + sum of contribution : %f ' % (bias[i] + np.sum(contributions[i])))    \n",
    "    print(\"-\"*20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
